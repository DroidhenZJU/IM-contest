{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import config\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---number of train sample---\n",
      "486\n",
      "---number of test sample---\n",
      "100\n",
      "---number of features---\n",
      "8027\n"
     ]
    }
   ],
   "source": [
    "train_filename = os.path.join(config.base_path, \"data\",\"train.xlsx\")\n",
    "test_filename = os.path.join(config.base_path, \"data\",\"测试A.xlsx\")\n",
    "train_raw = pd.read_excel(train_filename) #训练数据\n",
    "test_raw = pd.read_excel(test_filename) #测试数据\n",
    "train_data = train_raw.iloc[:,1:] \n",
    "train_data.index = train_raw.iloc[:,0].values\n",
    "test_data = test_raw.iloc[:,1:]\n",
    "test_data.index = test_raw.iloc[:,0].values\n",
    "\n",
    "print(\"---number of train sample---\")\n",
    "print(train_data.shape[0])\n",
    "print(\"---number of test sample---\")\n",
    "print(test_data.shape[0])\n",
    "print(\"---number of features---\")\n",
    "print(test_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fillna with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_col = train_data.mean()\n",
    "train_data_fillna = train_data.fillna(mean_col)\n",
    "mean_col = test_data.mean()\n",
    "test_data_fillna = test_data.fillna(mean_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onehot编码，删除一些重复的特征和时间戳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---number of features---\n",
      "6845\n"
     ]
    }
   ],
   "source": [
    "selected_features = [] #保留的特征\n",
    "dropped_features = [] #删除的特征\n",
    "for col in test_data_fillna.columns:\n",
    "    # 编码\n",
    "    x = np.hstack((train_data_fillna[col].values, test_data_fillna[col].values))\n",
    "    x_set_list = list(set(x))\n",
    "    # if col == '210X24':\n",
    "    #     print(x_set_list[0] / 10000000000)\n",
    "    #     exit()\n",
    "    if isinstance(x_set_list[0], str):\n",
    "        encode_dict = {}\n",
    "        for i in range(len(x_set_list)):\n",
    "            encode_dict[x_set_list[i]] = i\n",
    "        c_train = train_data_fillna[col]\n",
    "        for i in range(len(c_train)):\n",
    "            c_train.iat[i] = encode_dict[c_train.iat[i]]\n",
    "        c_test = test_data_fillna[col]\n",
    "        for i in range(len(c_test)):\n",
    "            c_test.iat[i] = encode_dict[c_test.iat[i]]\n",
    "    \n",
    "    #去重和去时间戳\n",
    "    x = train_data_fillna[col].values\n",
    "    x_set_list = list(set(x))\n",
    "\n",
    "    if len(x_set_list) >= 2 and not all([True if str(n) == \"nan\" else False for n in x]):\n",
    "        # if col == \"210X24\":\n",
    "        #     print(x_set_list[:20])\n",
    "        #     print(str(x_set_list[0]))\n",
    "        #     print([str(e).startswith(\"2017\") or str(e).startswith(\"2016\") for e in x_set_list[:20]])\n",
    "        if col == \"520X171\":\n",
    "            dropped_features.append(col)\n",
    "        elif not all([str(e).startswith(\"2017\") or str(e).startswith(\"2016\") for e in x_set_list[:20]]):\n",
    "            selected_features.append(col)\n",
    "        else:\n",
    "            dropped_features.append(col)\n",
    "    else:\n",
    "        dropped_features.append(col)\n",
    "df_train = train_data_fillna.loc[:, selected_features + ['Y']]\n",
    "df_test = test_data_fillna.loc[:, selected_features]\n",
    "\n",
    "print(\"---number of features---\")\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 按照相关系数筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_values = []\n",
    "k = 3000\n",
    "for col in df_test.columns:\n",
    "    corr_values.append(abs(pearsonr(df_train[col].values,df_train['Y'])[0]))\n",
    "corr_df = pd.DataFrame({'col':df_test.columns, 'corr_value':corr_values})\n",
    "corr_df = corr_df.sort_values(by='corr_value',ascending=False)\n",
    "selected = corr_df['col'].values[:k]\n",
    "\n",
    "df_train_corr = df_train.loc[:, list(selected) + ['Y']]\n",
    "df_test_corr = df_test.loc[:, list(selected)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照树模型筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Xgboost feature importance: 232th---\n",
      "0.00369004\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "X_train = df_train.values[:, 0:-1]\n",
    "Y_train = df_train.values[:,-1]\n",
    "X_test = df_test.values[:,:]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, random_state = 1024, test_size=0.1)\n",
    "\n",
    "# reg = GradientBoostingRegressor(random_state = 0,\n",
    "#                                 learning_rate = 0.1,\n",
    "#                                 n_estimators= 29,\n",
    "#                                 min_samples_split=2,\n",
    "#                                 min_samples_leaf=5,\n",
    "#                                 max_features=0.81,\n",
    "#                                 subsample= 0.8,\n",
    "#                                 max_depth= 6,\n",
    "# )\n",
    "reg = XGBRegressor(random_state = 0,\n",
    "                    learning_rate = 0.1,\n",
    "                    n_estimators= 49,\n",
    "                    subsample= 0.78,\n",
    "                    colsample_bytree= 0.62,\n",
    "                    max_depth= 3,\n",
    ")\n",
    "reg.fit(X_train, Y_train)\n",
    "sorted_imp = sorted(reg.feature_importances_, reverse=True)\n",
    "k = sorted_imp.index(0) - 1\n",
    "print(\"---Xgboost feature importance: %dth---\" %k)\n",
    "print(sorted_imp[k])\n",
    "importance_df = pd.DataFrame({'col':df_test.columns, 'importance':reg.feature_importances_})\n",
    "importance_df = importance_df.sort_values(by=\"importance\", ascending=False)\n",
    "selected = importance_df['col'].values[:k + 1]\n",
    "df_train_tree = df_train.loc[:, list(selected) + ['Y']]\n",
    "df_test_tree = df_test.loc[:, list(selected)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "after_file = os.path.join(config.base_path, \"data\", \"tree_feature_selected_xgboost_train_A.xlsx\")\n",
    "with pd.ExcelWriter(after_file) as writer:\n",
    "    df_train_tree.to_excel(writer,sheet_name = \"train_data\")\n",
    "    df_test_tree.to_excel(writer, sheet_name = \"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
